agent_log.sources=s1
agent_log.channels=ch0
agent_log.sinks=sink0

agent_log.sources.s1.channels=ch0
agent_log.sinks.sink0.channel=ch0

## set memory channel
agent_log.channels.ch0.type=memory
agent_log.channels.ch0.keep-alive=30
agent_log.channels.ch0.capacity=100000
agent_log.channels.ch0.transactionCapacity=100000

##set kafka config
agent_log.sources.s1.type=org.apache.flume.source.kafka.KafkaSource
agent_log.sources.s1.zookeeperConnect=10.1.3.107:2182,10.1.1.15:2182,10.1.1.44:2182,10.1.1.45:2182,10.1.1.46:2182,10.1.2.33:2182
agent_log.sources.s1.topic=app-content
agent_log.sources.s1.groupId=flume-app-content

#set etl  interceptor
agent_log.sources.s1.interceptors=YunyuAppcontentclicklog
agent_log.sources.s1.interceptors.YunyuAppcontentclicklog.type=cn.com.warlock.flume.interceptor.YunyuAppcontentclicklogInterceptor$Builder

## set hadoop hdfs config
agent_log.sinks.sink0.type=hdfs
agent_log.sinks.sink0.channel=ch0
agent_log.sinks.sink0.hdfs.path=/user/hive/warehouse/baby_bi.db/visitor_analysis/%Y-%m-%d
agent_log.sinks.sink0.hdfs.filePrefix=pre_app_content
agent_log.sinks.sink0.hdfs.minBlockReplicas=1
agent_log.sinks.sink0.hdfs.round=true
agent_log.sinks.sink0.hdfs.roundValue=1
agent_log.sinks.sink0.hdfs.roundUnit=day
agent_log.sinks.sink0.hdfs.useLocalTimeStamp=true
agent_log.sinks.sink0.hdfs.fileType=DataStream
agent_log.sinks.sink0.hdfs.batchSize=5000
agent_log.sinks.sink0.hdfs.writeFormat=Text
agent_log.sinks.sink0.hdfs.txnEventMax=30000
agent_log.sinks.sink0.hdfs.callTimeout=120000
agent_log.sinks.sink0.hdfs.idleTimeout=2000
agent_log.sinks.sink0.hdfs.appendTimeout=60000
agent_log.sinks.sink0.hdfs.rollSize=0
agent_log.sinks.sink0.hdfs.rollCount=1000
agent_log.sinks.sink0.hdfs.rollInterval=30